# Backtest Debug & Event Export System — Requirements

## 1. Overview

A unified event export system that serves three consumers from a single event stream:

1. **Visual Debugger** — real-time FE client connected via WebSocket, interactive step-through
2. **AI Debugger (Claude Code)** — post-hoc analysis via JSONL files + SQLite index
3. **Trade Logger** — persistent trade/order records, streamed as JSONL during the run, persisted to SQLite after run completes

The system supports multiple execution modes with different export filters, and handles concurrent parallel runs by writing to separate output directories.

---

## 2. Event Model

### 2.1 Canonical Event Shape

All events share a minimal envelope with compact field names:

| Field     | Key  | Type     | Description                                    |
|-----------|------|----------|------------------------------------------------|
| Timestamp | `ts` | ISO 8601 | UTC time of emission                           |
| Sequence  | `sq` | uint64   | Monotonic per-run, guarantees ordering         |
| Type      | `_t` | string   | Event type identifier (see §2.2)               |
| Source    | `src`| string   | Emitting component/subsystem                   |
| Data      | `d`  | object   | Event-specific payload, varies by `_t`         |

Run identity is not carried per-event. It is expressed by the containing directory (see §4).

Each event type is represented by a dedicated C# record type for compile-time safety. FE consumers may use dynamic typing if preferred.

### 2.2 Event Types

**Market data events:**
- `tick` — new tick received
- `bar` — new bar closed
- `bar.mut` — last (open) bar mutated (price update within forming bar)

**Indicator events:**
- `ind` — indicator value computed for a closed bar
- `ind.mut` — indicator value recomputed due to bar mutation

**Signal & risk events:**
- `sig` — signal generated by strategy logic
- `risk` — risk check performed (pass/reject + reason)

**Order lifecycle events:**
- `ord.place` — order submitted
- `ord.fill` — order filled (partial or full)
- `ord.cancel` — order cancelled
- `ord.reject` — order rejected
- `pos` — position changed

**System events:**
- `run.start` — run began (includes config/params snapshot)
- `run.end` — run completed (includes summary stats)
- `err` — error
- `warn` — warning

### 2.3 Export Mode Tags

Each event type is annotated in code with a non-exported `[Flags] enum ExportMode` that determines in which execution contexts the event is emitted:

```
[Flags]
enum ExportMode
{
    Backtest     = 1,
    Optimization = 2,
    Live         = 4,
}
```

Configuration is per event type, defined in code (not runtime config):

| Event type(s)                        | Default ExportMode               | Rationale                                         |
|--------------------------------------|----------------------------------|----------------------------------------------------|
| `ord.*`, `pos`                       | Backtest \| Optimization \| Live | Trade activity is always captured                  |
| `sig`, `risk`                        | Backtest \| Live                 | Decision logic — relevant for debugging, not for mass optimization |
| `bar`, `ind`                         | Backtest                         | Data-level events — debug only                     |
| `tick`                               | Backtest (opt-in)                | Very verbose, only when explicitly needed          |
| `bar.mut`, `ind.mut`                 | Backtest (opt-in)                | Mutation events generate high noise; rarely needed  |
| `run.start`, `run.end`              | Backtest \| Optimization \| Live | Always present as bookends                         |
| `err`, `warn`                        | Backtest \| Optimization \| Live | Always captured                                    |

The event bus checks `eventType.ExportMode.HasFlag(currentRunMode)` before serialization. Events that don't match are silently dropped — never serialized, never written to any sink.

### 2.4 Data Subscription Export Control

Bar and indicator export is governed by the `DataSubscription` configuration:

```csharp
public record DataSubscription(Asset Asset, TimeSpan TimeFrame, bool IsExportable = false);
```

A strategy declares one or more data subscriptions (e.g. ETH-USD M1, ETH-USD H1, BTC-USD H4). Only subscriptions with `IsExportable = true` have their `bar`, `bar.mut`, `ind`, and `ind.mut` events emitted to sinks. Non-exportable subscriptions are still processed internally by the strategy but produce no event output.

This allows fine-grained control in multi-asset, multi-timeframe strategies. For example, a strategy consuming M1 bars for signal calculation but operating on H1 decisions would mark only the H1 subscription as exportable — avoiding noise from 60x more M1 bar events.

The visual debugger draws and steps through bars from exportable subscriptions only. Post-run reports likewise use exportable subscriptions for charting.

---

## 3. Event Bus Architecture

### 3.1 Single Emission Point

Strategy code, indicators, execution engine, and risk manager all emit events through a single `IEventBus` abstraction. The bus:

- Checks `ExportMode` tag against the current run mode — drops non-matching events
- Applies `DataSubscription.IsExportable` filter for bar/indicator events — only emits from exportable subscriptions
- Serializes each surviving event to JSON **once**
- Fans out the serialized payload to all registered sinks

### 3.2 Sinks

| Sink | Purpose | Receives |
|------|---------|----------|
| **JSONL File Sink** | Post-hoc AI/human analysis | All exported events (after mode + TF filtering) |
| **WebSocket Sink** | Real-time FE visual debugger | All exported events (after mode + TF filtering) |

Trade logging is not a separate sink — trade events (`ord.*`, `pos`) flow through the same JSONL file sink as all other events. They are extracted into the Trade DB during post-run index build (see §6).

---

## 4. File Organization & Run Identity

The following structure should be in the same AlgoTradeForge dir (..AppData/localAlgoTradeForge on Windows) that contains partitioned Candle data from CandleIngestor.

### 4.1 Directory Structure

```
Data/
  EventLogs/
    {run_folder_name}/
      events.jsonl        # complete chronological event stream
      meta.json           # run config, params, summary (written at run.end)
      index.sqlite        # AI debug query index (built post-run, if enabled)
  trades.sqlite           # persistent trade DB, shared across all runs
```

### 4.2 Run Folder Naming

Run identity is encoded in the folder name, not in individual events. The folder name is a human-readable identifier:

```
{strategy_name}_v{version}_{asset}_{period}_{params_hash}_{timestamp}
```

Examples:
```
MeanRevert_v2.3_ETH-USD_H1_2024-2025_a3f8c1_20260208T143201
TrendFollow_v1.0_BTC-USD_M15_2025-2026_b7d2e4_20260208T150000
```

Components:
- `strategy_name` + `version` — human-readable identification
- `asset` + `period` — the primary backtest parameters
- `params_hash` — short hash of the full parameter set (for uniqueness when same strategy/asset runs with different params)
- `timestamp` — run start time (prevents collision on re-runs)

The full parameter set is stored inside `meta.json`, not in the folder name.

### 4.3 Parallel Run Isolation

Each concurrent run (e.g. during optimization) writes to its own directory. There is no shared file or stream between runs. Isolation is structural (separate directories), not logical (filtering by run ID within a shared stream).

---

## 5. WebSocket Interface (Visual Debugger)

### 5.1 Connection Model

The backtest runner hosts a WebSocket server. The FE client connects to a specific run's channel.

- One WebSocket connection per observed run
- Events are pushed to the client as they are emitted (same JSON as file sink)
- If no FE client is connected, the sink is a no-op (events still go to file)

### 5.2 Execution Control via WebSocket

The FE client sends **control messages** to govern execution flow. The runner starts in **paused** state when a visual debug session is active.

**Control commands:**

| Command | Payload | Behavior |
|---------|---------|----------|
| `continue` | — | Run to completion without pausing |
| `next` | — | Advance to the next exported event (any type), then pause |
| `next_type` | `{ "_t": "bar" }` | Advance until the next event of the given type is exported, then pause |
| `next_bar` | — | Shortcut: advance to next `bar` event from any exportable subscription, then pause |
| `next_signal` | — | Shortcut: advance to next `sig` event, then pause |
| `next_trade` | — | Advance until next order lifecycle event, then pause |
| `run_to` | `{ "sq": 5000 }` or `{ "ts": "..." }` | Run until a specific sequence number or timestamp, then pause |
| `set_export` | `{ "mutations": true }` | Toggle opt-in event categories mid-run (e.g. enable `bar.mut`, `ind.mut`) |
| `pause` | — | Pause execution after the current event completes |

All stepping commands operate on **exported** events only (post-filter). `next_bar` steps to the next bar from any exportable `DataSubscription`, skipping bars from non-exportable subscriptions.

### 5.3 Pause Semantics

When paused, the runner:

- Has fully processed and emitted the current event
- Holds all state (open positions, indicator buffers, current bar) in memory
- Waits for the next control command before advancing
- Remains responsive to WebSocket control messages

When `continue` is issued, the runner stops pausing between events and runs at full speed, still emitting events to all sinks in real-time.

### 5.4 No-Client Mode

When running without a visual debugger (normal backtest or optimization), the WebSocket server is either not started or execution is in `continue` mode by default (no pausing). Determined by run configuration.

---

## 6. Post-Run Persistence

Both persistent stores are built from the JSONL event stream after the run completes or is interrupted. During the run, only JSONL is written (plus WebSocket emission if active).

### 6.1 AI Debug Index (index.sqlite)

**Trigger:** built post-run **if enabled in backtest settings**. Not built for optimization runs by default.

**Source:** parses the run's `events.jsonl`.

**Schema:**
- `events` table — all events with extracted top-level fields (`sq`, `ts`, `_t`, `src`) as indexed columns + full JSON in a `raw` column
- Indexed on: `sq`, `ts`, `_t`, `src`

**Location:** `Data/EventLogs/{run_folder}/index.sqlite` — co-located with the JSONL it indexes.

**Crash resilience:** if the run terminates abnormally, the JSONL file is the only artifact. The index can be rebuilt later manually or by a utility command operating on the existing JSONL.

### 6.2 Trade DB (trades.sqlite)

**Trigger:** built post-run **always**, for every execution mode (backtest, optimization, live).

**Source:** extracts `ord.*` and `pos` events from the run's `events.jsonl`.

**Schema:**
- `runs` table — run folder name, strategy, version, asset, period, full params (JSON), start/end time, mode, summary stats
- `orders` table — FK to run, full order lifecycle
- `trades` table — FK to order, individual fills

**Location:** `Data/trades.sqlite` — single shared file across all runs.

**Write behavior:** inserts transactionally after the run completes. For optimization with many parallel runs, each run's trade data is inserted in a single transaction upon that run's completion.

**Crash resilience:** if the run terminates abnormally, trade data can still be recovered by re-extracting from the JSONL (same as index build).

### 6.3 Lifecycle Summary

```
During run:      events.jsonl ← append (+ WebSocket push if visual debug)
                 meta.json ← written at run.end

After run:       events.jsonl → index.sqlite    (if enabled)
                 events.jsonl → trades.sqlite   (always)
```

---

## 7. Execution Modes Summary

| Mode | JSONL Export | AI Debug Index | Trade DB | WebSocket | Default Export |
|------|-------------|----------------|----------|-----------|----------------|
| **Debug (visual)** | ✓ | ✓ | ✓ | ✓ (paused start) | `Backtest` flag events |
| **Debug (AI/headless)** | ✓ | ✓ | ✓ | ✗ | `Backtest` flag events |
| **Backtest** | ✓ | Optional | ✓ | ✗ | `Backtest` flag events |
| **Optimization** | ✓ (trades only) | ✗ | ✓ | ✗ | `Optimization` flag events |
| **Prod / Paper** | ✓ | ✗ | ✓ | ✗ | `Live` flag events |

---

## 8. AI Debugger Experience (Claude Code)

### 8.1 Available Artifacts Per Run

Claude Code has access to:

1. `meta.json` — read first, understand what the run was
2. `events.jsonl` — sequential reading for narrative debugging
3. `index.sqlite` — SQL queries for analytical debugging (if built)
4. Skill file documenting the event schema, file layout, and recommended workflows

### 8.2 Expected Debugging Workflows

- **Triage:** read `meta.json` summary → query `index.sqlite` for error/warning count → read those events from JSONL for context
- **Execution debugging:** query orders from `index.sqlite` → find sequence range → read surrounding events from JSONL to see what led to the order
- **Indicator debugging:** query specific indicator values from `index.sqlite` → compare expected vs actual → read raw bar data around anomalies
- **Comparison across runs:** query `index.sqlite` from two runs → diff trade outcomes → investigate divergence points in JSONL

### 8.3 Skill File Contract

A skill file (`SKILL.md`) is provided that documents:
- Event envelope schema and compact field names
- All event types and their `d` (data) payload shapes
- File layout and naming conventions
- Recommended `jq` and `sqlite3` query patterns
- Debugging workflow decision tree (start here → then check this → then look at that)

---

## 9. Design Decisions Log

| # | Decision | Rationale |
|---|----------|-----------|
| 1 | Flag enum `ExportMode` over logging levels | Export is per-event-type configuration, not a severity hierarchy. A bar event isn't "less important" than a trade — it's relevant in different contexts. |
| 2 | `DataSubscription.IsExportable` flag over global reporting timeframe | Per-subscription export control supports multi-asset, multi-TF strategies naturally. No single "reporting TF" assumption — each subscription decides independently. |
| 3 | No run ID in event payload | Run identity is structural (directory), not per-event metadata. Eliminates redundant bytes and simplifies the event model. |
| 4 | Single chronological JSONL, no partitioning | Preserves narrative flow for LLM sequential reasoning. SQLite index provides type-based access post-hoc. |
| 5 | JSONL as source of truth, SQLite as derived | Simplifies the write path (append-only file). Both indexes are built from the same source after run completion. |
| 6 | Trade DB shared across runs | Enables cross-run queries (all ETH-USD trades across strategy versions) without opening N directories. |
| 7 | Strictly typed C# records per event type | Compile-time safety for event payloads. FE may use dynamic typing independently. |